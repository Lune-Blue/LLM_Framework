[34m[1mwandb[0m: [33mWARNING[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
[2025-01-10 13:30:10,351] [INFO] [axolotl.callbacks.on_train_begin:812] [PID:2652322] [RANK:0] The Axolotl config has been saved to the WandB run under files.[39m
  0%|                                                                                                                                                                  | 0/230 [00:00<?, ?it/s]You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
                                                                                                                                                                                               
{'loss': 1.6389, 'grad_norm': 0.7217003107070923, 'learning_rate': 2e-05, 'epoch': 0.02}
                                                                                                                                                                                               
[2025-01-10 13:30:12,529] [INFO] [accelerate.accelerator.gather_for_metrics:2509] [PID:2652322] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.
{'eval_loss': 1.9754905700683594, 'eval_runtime': 1.544, 'eval_samples_per_second': 90.026, 'eval_steps_per_second': 5.829, 'epoch': 0.02}
[2025-01-10 13:30:12,997] [INFO] [axolotl.callbacks.on_step_end:128] [PID:2652322] [RANK:0] cuda memory usage while training: 2.424GB (+15.593GB cache, +0.978GB misc)[39m
{'loss': 1.6391, 'grad_norm': 0.6519946455955505, 'learning_rate': 4e-05, 'epoch': 0.04}
{'loss': 1.6348, 'grad_norm': 0.5649563074111938, 'learning_rate': 6e-05, 'epoch': 0.07}
{'loss': 1.7054, 'grad_norm': 0.6424350142478943, 'learning_rate': 8e-05, 'epoch': 0.09}
{'loss': 1.6145, 'grad_norm': 0.6151083707809448, 'learning_rate': 0.0001, 'epoch': 0.11}
{'loss': 1.5883, 'grad_norm': 0.5756988525390625, 'learning_rate': 0.00012, 'epoch': 0.13}
{'loss': 1.4861, 'grad_norm': 0.4720902740955353, 'learning_rate': 0.00014, 'epoch': 0.15}
{'loss': 1.5521, 'grad_norm': 0.5819863677024841, 'learning_rate': 0.00016, 'epoch': 0.17}
{'loss': 1.4042, 'grad_norm': 0.6700189113616943, 'learning_rate': 0.00018, 'epoch': 0.2}
{'loss': 1.4021, 'grad_norm': 0.6953012347221375, 'learning_rate': 0.0002, 'epoch': 0.22}
{'loss': 1.445, 'grad_norm': 0.7199373245239258, 'learning_rate': 0.00019998980430094334, 'epoch': 0.24}
{'loss': 1.4092, 'grad_norm': 0.5488927960395813, 'learning_rate': 0.00019995921928281894, 'epoch': 0.26}
{'loss': 1.4062, 'grad_norm': 0.5431457757949829, 'learning_rate': 0.00019990825118233957, 'epoch': 0.28}
{'loss': 1.3189, 'grad_norm': 0.49640029668807983, 'learning_rate': 0.00019983691039261357, 'epoch': 0.3}
{'loss': 1.3278, 'grad_norm': 0.47457364201545715, 'learning_rate': 0.00019974521146102537, 'epoch': 0.33}
{'loss': 1.3555, 'grad_norm': 0.430841863155365, 'learning_rate': 0.00019963317308626914, 'epoch': 0.35}
{'loss': 1.2516, 'grad_norm': 0.3754154145717621, 'learning_rate': 0.00019950081811453597, 'epoch': 0.37}
{'loss': 1.3243, 'grad_norm': 0.4313296377658844, 'learning_rate': 0.00019934817353485501, 'epoch': 0.39}
{'loss': 1.2301, 'grad_norm': 0.4633715748786926, 'learning_rate': 0.00019917527047359028, 'epoch': 0.41}
{'loss': 1.2456, 'grad_norm': 0.3998909294605255, 'learning_rate': 0.0001989821441880933, 'epoch': 0.43}
{'loss': 1.283, 'grad_norm': 0.4144320487976074, 'learning_rate': 0.00019876883405951377, 'epoch': 0.46}
{'loss': 1.2922, 'grad_norm': 0.4212415814399719, 'learning_rate': 0.00019853538358476932, 'epoch': 0.48}
{'loss': 1.2451, 'grad_norm': 0.4144607484340668, 'learning_rate': 0.00019828184036767556, 'epoch': 0.5}
{'loss': 1.2207, 'grad_norm': 0.3832094073295593, 'learning_rate': 0.00019800825610923934, 'epoch': 0.52}
{'loss': 1.1593, 'grad_norm': 0.3976329267024994, 'learning_rate': 0.00019771468659711595, 'epoch': 0.54}
{'loss': 1.207, 'grad_norm': 0.419437438249588, 'learning_rate': 0.00019740119169423337, 'epoch': 0.57}
{'loss': 1.2109, 'grad_norm': 0.45769003033638, 'learning_rate': 0.00019706783532658526, 'epoch': 0.59}
{'loss': 1.2153, 'grad_norm': 0.41970252990722656, 'learning_rate': 0.00019671468547019573, 'epoch': 0.61}
{'loss': 1.185, 'grad_norm': 0.36374756693840027, 'learning_rate': 0.0001963418141372579, 'epoch': 0.63}
{'loss': 1.2129, 'grad_norm': 0.4379407465457916, 'learning_rate': 0.00019594929736144976, 'epoch': 0.65}
{'loss': 1.1832, 'grad_norm': 0.40669599175453186, 'learning_rate': 0.00019553721518242968, 'epoch': 0.67}
{'loss': 1.1492, 'grad_norm': 0.3921920955181122, 'learning_rate': 0.00019510565162951537, 'epoch': 0.7}
{'loss': 1.1647, 'grad_norm': 0.3872149884700775, 'learning_rate': 0.000194654694704549, 'epoch': 0.72}
{'loss': 1.2473, 'grad_norm': 0.4247511327266693, 'learning_rate': 0.00019418443636395248, 'epoch': 0.74}
{'loss': 1.1736, 'grad_norm': 0.37212836742401123, 'learning_rate': 0.0001936949724999762, 'epoch': 0.76}
{'loss': 1.1249, 'grad_norm': 0.38515931367874146, 'learning_rate': 0.00019318640292114524, 'epoch': 0.78}
{'loss': 1.1737, 'grad_norm': 0.43350276350975037, 'learning_rate': 0.00019265883133190713, 'epoch': 0.8}
{'loss': 1.1717, 'grad_norm': 0.44811370968818665, 'learning_rate': 0.000192112365311485, 'epoch': 0.83}
{'loss': 1.1436, 'grad_norm': 0.4293529987335205, 'learning_rate': 0.00019154711629194062, 'epoch': 0.85}
{'loss': 1.1775, 'grad_norm': 0.4488319754600525, 'learning_rate': 0.00019096319953545185, 'epoch': 0.87}
{'loss': 1.1453, 'grad_norm': 0.45843684673309326, 'learning_rate': 0.00019036073411080916, 'epoch': 0.89}
{'loss': 1.1639, 'grad_norm': 0.4479439854621887, 'learning_rate': 0.00018973984286913584, 'epoch': 0.91}
{'loss': 1.1607, 'grad_norm': 0.4054909646511078, 'learning_rate': 0.0001891006524188368, 'epoch': 0.93}
{'loss': 1.175, 'grad_norm': 0.40555956959724426, 'learning_rate': 0.00018844329309978145, 'epoch': 0.96}
{'loss': 1.1261, 'grad_norm': 0.43724524974823, 'learning_rate': 0.00018776789895672558, 'epoch': 0.98}
{'loss': 1.1554, 'grad_norm': 0.4471496641635895, 'learning_rate': 0.00018707460771197774, 'epoch': 1.0}
{'loss': 1.1029, 'grad_norm': 0.4032590687274933, 'learning_rate': 0.0001863635607373157, 'epoch': 1.02}
{'loss': 1.0745, 'grad_norm': 0.3809088170528412, 'learning_rate': 0.0001856349030251589, 'epoch': 1.04}
{'loss': 1.1414, 'grad_norm': 0.41729578375816345, 'learning_rate': 0.00018488878315900227, 'epoch': 1.07}
{'loss': 1.1002, 'grad_norm': 0.41833674907684326, 'learning_rate': 0.00018412535328311814, 'epoch': 1.09}
{'loss': 1.0689, 'grad_norm': 0.41668620705604553, 'learning_rate': 0.00018334476907153177, 'epoch': 1.11}
{'loss': 1.0873, 'grad_norm': 0.448542982339859, 'learning_rate': 0.0001825471896962774, 'epoch': 1.13}
{'loss': 1.0833, 'grad_norm': 0.4451584219932556, 'learning_rate': 0.0001817327777949407, 'epoch': 1.15}
{'loss': 1.0289, 'grad_norm': 0.4200083017349243, 'learning_rate': 0.00018090169943749476, 'epoch': 1.17}
{'loss': 1.0785, 'grad_norm': 0.44636645913124084, 'learning_rate': 0.00018005412409243606, 'epoch': 1.2}
{'loss': 1.0753, 'grad_norm': 0.45651745796203613, 'learning_rate': 0.00017919022459222752, 'epoch': 1.22}
{'loss': 1.0489, 'grad_norm': 0.4066723585128784, 'learning_rate': 0.00017831017709805556, 'epoch': 1.24}
{'loss': 1.073, 'grad_norm': 0.403977632522583, 'learning_rate': 0.00017741416106390826, 'epoch': 1.26}
{'loss': 1.0909, 'grad_norm': 0.4521481990814209, 'learning_rate': 0.00017650235919998232, 'epoch': 1.28}
{'loss': 1.0479, 'grad_norm': 0.47095608711242676, 'learning_rate': 0.00017557495743542585, 'epoch': 1.3}
{'loss': 1.0452, 'grad_norm': 0.4517096281051636, 'learning_rate': 0.00017463214488042472, 'epoch': 1.33}
{'loss': 1.0702, 'grad_norm': 0.4506318271160126, 'learning_rate': 0.0001736741137876405, 'epoch': 1.35}
{'loss': 1.0989, 'grad_norm': 0.5265313386917114, 'learning_rate': 0.00017270105951300738, 'epoch': 1.37}
{'loss': 1.0656, 'grad_norm': 0.45318603515625, 'learning_rate': 0.00017171318047589637, 'epoch': 1.39}
{'loss': 1.0548, 'grad_norm': 0.45975008606910706, 'learning_rate': 0.00017071067811865476, 'epoch': 1.41}
{'loss': 1.078, 'grad_norm': 0.4334137737751007, 'learning_rate': 0.00016969375686552937, 'epoch': 1.43}
{'loss': 1.1041, 'grad_norm': 0.5123745203018188, 'learning_rate': 0.00016866262408098134, 'epoch': 1.46}
{'loss': 1.0118, 'grad_norm': 0.4465521574020386, 'learning_rate': 0.00016761749002740193, 'epoch': 1.48}
{'loss': 1.0254, 'grad_norm': 0.4813992381095886, 'learning_rate': 0.00016655856782223682, 'epoch': 1.5}
{'loss': 1.0596, 'grad_norm': 0.4697032570838928, 'learning_rate': 0.00016548607339452853, 'epoch': 1.52}
{'loss': 1.0677, 'grad_norm': 0.4632361829280853, 'learning_rate': 0.00016440022544088553, 'epoch': 1.54}
{'loss': 1.0336, 'grad_norm': 0.4352371394634247, 'learning_rate': 0.00016330124538088705, 'epoch': 1.57}
{'loss': 1.0654, 'grad_norm': 0.5057992339134216, 'learning_rate': 0.00016218935731193224, 'epoch': 1.59}
{'loss': 1.0814, 'grad_norm': 0.49000388383865356, 'learning_rate': 0.00016106478796354382, 'epoch': 1.61}
{'loss': 1.083, 'grad_norm': 0.46406814455986023, 'learning_rate': 0.0001599277666511347, 'epoch': 1.63}
{'loss': 1.1062, 'grad_norm': 0.4665946662425995, 'learning_rate': 0.00015877852522924732, 'epoch': 1.65}
{'loss': 1.0592, 'grad_norm': 0.459994375705719, 'learning_rate': 0.0001576172980442753, 'epoch': 1.67}
{'loss': 1.0509, 'grad_norm': 0.5011565685272217, 'learning_rate': 0.00015644432188667695, 'epoch': 1.7}
{'loss': 1.0079, 'grad_norm': 0.4721566140651703, 'learning_rate': 0.00015525983594269027, 'epoch': 1.72}
{'loss': 1.0549, 'grad_norm': 0.45991936326026917, 'learning_rate': 0.00015406408174555976, 'epoch': 1.74}
{'loss': 1.0198, 'grad_norm': 0.49402502179145813, 'learning_rate': 0.0001528573031262842, 'epoch': 1.76}
{'loss': 1.0075, 'grad_norm': 0.5031941533088684, 'learning_rate': 0.0001516397461638962, 'epoch': 1.78}
{'loss': 0.9918, 'grad_norm': 0.5294327735900879, 'learning_rate': 0.0001504116591352832, 'epoch': 1.8}
{'loss': 1.0635, 'grad_norm': 0.512374997138977, 'learning_rate': 0.0001491732924645604, 'epoch': 1.83}
{'loss': 1.0399, 'grad_norm': 0.4572465717792511, 'learning_rate': 0.0001479248986720057, 'epoch': 1.85}
{'loss': 1.0486, 'grad_norm': 0.5114506483078003, 'learning_rate': 0.00014666673232256738, 'epoch': 1.87}
{'loss': 1.1185, 'grad_norm': 0.508858323097229, 'learning_rate': 0.00014539904997395468, 'epoch': 1.89}
{'loss': 0.9865, 'grad_norm': 0.46440985798835754, 'learning_rate': 0.00014412211012432212, 'epoch': 1.91}
{'loss': 1.0898, 'grad_norm': 0.5705903172492981, 'learning_rate': 0.00014283617315955814, 'epoch': 1.93}
{'loss': 1.037, 'grad_norm': 0.48892802000045776, 'learning_rate': 0.00014154150130018866, 'epoch': 1.96}
{'loss': 1.061, 'grad_norm': 0.4980829954147339, 'learning_rate': 0.0001402383585479068, 'epoch': 1.98}
{'loss': 1.044, 'grad_norm': 0.4799138307571411, 'learning_rate': 0.00013892701063173918, 'epoch': 2.0}
{'loss': 1.0357, 'grad_norm': 0.4824245870113373, 'learning_rate': 0.00013760772495385998, 'epoch': 2.02}
{'loss': 0.9756, 'grad_norm': 0.4376600682735443, 'learning_rate': 0.0001362807705350641, 'epoch': 2.02}
{'loss': 0.9811, 'grad_norm': 0.47698163986206055, 'learning_rate': 0.00013494641795990986, 'epoch': 2.04}
{'loss': 0.9857, 'grad_norm': 0.43481719493865967, 'learning_rate': 0.00013360493932154302, 'epoch': 2.07}
{'loss': 0.9957, 'grad_norm': 0.4655703902244568, 'learning_rate': 0.0001322566081662134, 'epoch': 2.09}
{'loss': 0.9663, 'grad_norm': 0.5249767303466797, 'learning_rate': 0.00013090169943749476, 'epoch': 2.11}
{'loss': 1.006, 'grad_norm': 0.490070641040802, 'learning_rate': 0.00012954048942022002, 'epoch': 2.13}
{'loss': 0.9475, 'grad_norm': 0.502957284450531, 'learning_rate': 0.00012817325568414297, 'epoch': 2.15}
{'loss': 0.9981, 'grad_norm': 0.503093957901001, 'learning_rate': 0.0001268002770273379, 'epoch': 2.17}
{'loss': 0.9846, 'grad_norm': 0.528393030166626, 'learning_rate': 0.00012542183341934872, 'epoch': 2.2}
{'loss': 0.9407, 'grad_norm': 0.5385774970054626, 'learning_rate': 0.00012403820594409924, 'epoch': 2.22}
{'loss': 1.008, 'grad_norm': 0.5407642722129822, 'learning_rate': 0.00012264967674257646, 'epoch': 2.24}
{'loss': 0.9581, 'grad_norm': 0.5152865648269653, 'learning_rate': 0.00012125652895529766, 'epoch': 2.26}
{'loss': 0.9621, 'grad_norm': 0.5313097834587097, 'learning_rate': 0.00011985904666457455, 'epoch': 2.28}
{'loss': 0.9476, 'grad_norm': 0.5029342174530029, 'learning_rate': 0.00011845751483658453, 'epoch': 2.3}
{'loss': 0.9737, 'grad_norm': 0.5043742656707764, 'learning_rate': 0.0001170522192632624, 'epoch': 2.33}
{'loss': 0.9798, 'grad_norm': 0.5015596151351929, 'learning_rate': 0.0001156434465040231, 'epoch': 2.35}
{'loss': 0.9577, 'grad_norm': 0.5354365110397339, 'learning_rate': 0.00011423148382732853, 'epoch': 2.37}
{'loss': 0.9385, 'grad_norm': 0.5146118998527527, 'learning_rate': 0.0001128166191521093, 'epoch': 2.39}
{'loss': 0.954, 'grad_norm': 0.5043328404426575, 'learning_rate': 0.00011139914098905406, 'epoch': 2.41}
{'loss': 0.9624, 'grad_norm': 0.5284929871559143, 'learning_rate': 0.00010997933838177827, 'epoch': 2.43}
{'loss': 0.9696, 'grad_norm': 0.5307461619377136, 'learning_rate': 0.00010855750084788398, 'epoch': 2.46}
{'loss': 0.9808, 'grad_norm': 0.5272848010063171, 'learning_rate': 0.00010713391831992323, 'epoch': 2.48}
{'loss': 1.0171, 'grad_norm': 0.5527021884918213, 'learning_rate': 0.00010570888108627681, 'epoch': 2.5}
{'loss': 0.9239, 'grad_norm': 0.5685996413230896, 'learning_rate': 0.00010428267973196027, 'epoch': 2.52}
{'loss': 0.9514, 'grad_norm': 0.49599042534828186, 'learning_rate': 0.00010285560507936961, 'epoch': 2.54}
{'loss': 0.9443, 'grad_norm': 0.546212375164032, 'learning_rate': 0.00010142794812897873, 'epoch': 2.57}
{'loss': 0.9818, 'grad_norm': 0.5328400731086731, 'learning_rate': 0.0001, 'epoch': 2.59}
{'loss': 0.955, 'grad_norm': 0.5286722183227539, 'learning_rate': 9.85720518710213e-05, 'epoch': 2.61}
{'loss': 0.9451, 'grad_norm': 0.5402013659477234, 'learning_rate': 9.71443949206304e-05, 'epoch': 2.63}
{'loss': 0.9676, 'grad_norm': 0.5343837738037109, 'learning_rate': 9.571732026803977e-05, 'epoch': 2.65}
{'loss': 0.9697, 'grad_norm': 0.5467099547386169, 'learning_rate': 9.42911189137232e-05, 'epoch': 2.67}
{'loss': 0.9721, 'grad_norm': 0.5344420075416565, 'learning_rate': 9.286608168007678e-05, 'epoch': 2.7}
{'loss': 0.9568, 'grad_norm': 0.5312094688415527, 'learning_rate': 9.144249915211605e-05, 'epoch': 2.72}
{'loss': 0.9281, 'grad_norm': 0.5299472808837891, 'learning_rate': 9.002066161822172e-05, 'epoch': 2.74}
{'loss': 0.9374, 'grad_norm': 0.55150306224823, 'learning_rate': 8.860085901094595e-05, 'epoch': 2.76}
{'loss': 0.9966, 'grad_norm': 0.5447680354118347, 'learning_rate': 8.718338084789072e-05, 'epoch': 2.78}
{'loss': 0.9555, 'grad_norm': 0.5623309016227722, 'learning_rate': 8.57685161726715e-05, 'epoch': 2.8}
{'loss': 1.0116, 'grad_norm': 0.5428453683853149, 'learning_rate': 8.435655349597689e-05, 'epoch': 2.83}
{'loss': 0.9821, 'grad_norm': 0.5529402494430542, 'learning_rate': 8.294778073673762e-05, 'epoch': 2.85}
{'loss': 0.9884, 'grad_norm': 0.5428875088691711, 'learning_rate': 8.154248516341548e-05, 'epoch': 2.87}
{'loss': 0.9784, 'grad_norm': 0.5706819295883179, 'learning_rate': 8.014095333542548e-05, 'epoch': 2.89}
{'loss': 0.961, 'grad_norm': 0.5282888412475586, 'learning_rate': 7.874347104470234e-05, 'epoch': 2.91}
{'loss': 0.9941, 'grad_norm': 0.5593986511230469, 'learning_rate': 7.735032325742355e-05, 'epoch': 2.93}
{'loss': 0.9684, 'grad_norm': 0.5000099539756775, 'learning_rate': 7.596179405590076e-05, 'epoch': 2.96}
{'loss': 0.9394, 'grad_norm': 0.4963131844997406, 'learning_rate': 7.457816658065134e-05, 'epoch': 2.98}
{'loss': 0.9336, 'grad_norm': 0.5436190962791443, 'learning_rate': 7.319972297266214e-05, 'epoch': 3.0}
{'loss': 0.9258, 'grad_norm': 0.49697041511535645, 'learning_rate': 7.182674431585704e-05, 'epoch': 3.02}
{'loss': 0.918, 'grad_norm': 0.4970821142196655, 'learning_rate': 7.045951057978e-05, 'epoch': 3.02}
{'loss': 0.907, 'grad_norm': 0.5235177874565125, 'learning_rate': 6.909830056250527e-05, 'epoch': 3.04}
{'loss': 0.8891, 'grad_norm': 0.5668990015983582, 'learning_rate': 6.774339183378663e-05, 'epoch': 3.07}
{'loss': 0.9077, 'grad_norm': 0.530218780040741, 'learning_rate': 6.639506067845697e-05, 'epoch': 3.09}
{'loss': 0.9265, 'grad_norm': 0.5249951481819153, 'learning_rate': 6.505358204009017e-05, 'epoch': 3.11}
{'loss': 0.9272, 'grad_norm': 0.5688856244087219, 'learning_rate': 6.371922946493591e-05, 'epoch': 3.13}
{'loss': 0.9012, 'grad_norm': 0.5313314199447632, 'learning_rate': 6.239227504614003e-05, 'epoch': 3.15}
{'loss': 0.9498, 'grad_norm': 0.5918875336647034, 'learning_rate': 6.107298936826086e-05, 'epoch': 3.17}
{'loss': 0.8725, 'grad_norm': 0.5635277628898621, 'learning_rate': 5.976164145209322e-05, 'epoch': 3.2}
{'loss': 0.9075, 'grad_norm': 0.5642642378807068, 'learning_rate': 5.845849869981137e-05, 'epoch': 3.22}
{'loss': 0.909, 'grad_norm': 0.6354354619979858, 'learning_rate': 5.71638268404419e-05, 'epoch': 3.24}
{'loss': 0.8612, 'grad_norm': 0.5930721163749695, 'learning_rate': 5.5877889875677845e-05, 'epoch': 3.26}
{'loss': 0.8881, 'grad_norm': 0.6073926687240601, 'learning_rate': 5.4600950026045326e-05, 'epoch': 3.28}
{'loss': 0.87, 'grad_norm': 0.5267605185508728, 'learning_rate': 5.333326767743263e-05, 'epoch': 3.3}
{'loss': 0.8856, 'grad_norm': 0.557837188243866, 'learning_rate': 5.207510132799436e-05, 'epoch': 3.33}
{'loss': 0.8764, 'grad_norm': 0.5467550158500671, 'learning_rate': 5.082670753543961e-05, 'epoch': 3.35}
{'loss': 0.8971, 'grad_norm': 0.5763828158378601, 'learning_rate': 4.958834086471683e-05, 'epoch': 3.37}
{'loss': 0.8815, 'grad_norm': 0.5773867964744568, 'learning_rate': 4.836025383610382e-05, 'epoch': 3.39}
{'loss': 0.9314, 'grad_norm': 0.538856029510498, 'learning_rate': 4.714269687371581e-05, 'epoch': 3.41}
{'loss': 0.8916, 'grad_norm': 0.5760659575462341, 'learning_rate': 4.593591825444028e-05, 'epoch': 3.43}
{'loss': 0.88, 'grad_norm': 0.5468153953552246, 'learning_rate': 4.474016405730973e-05, 'epoch': 3.46}
{'loss': 0.9269, 'grad_norm': 0.5839794278144836, 'learning_rate': 4.355567811332311e-05, 'epoch': 3.48}
{'loss': 0.9142, 'grad_norm': 0.5920402407646179, 'learning_rate': 4.238270195572472e-05, 'epoch': 3.5}
{'loss': 0.9126, 'grad_norm': 0.6144497394561768, 'learning_rate': 4.12214747707527e-05, 'epoch': 3.52}
{'loss': 0.9901, 'grad_norm': 0.608234703540802, 'learning_rate': 4.007223334886531e-05, 'epoch': 3.54}
{'loss': 0.9168, 'grad_norm': 0.5872846245765686, 'learning_rate': 3.893521203645618e-05, 'epoch': 3.57}
{'loss': 0.8764, 'grad_norm': 0.5685776472091675, 'learning_rate': 3.7810642688067796e-05, 'epoch': 3.59}
{'loss': 0.9003, 'grad_norm': 0.5622550845146179, 'learning_rate': 3.669875461911297e-05, 'epoch': 3.61}
{'loss': 0.8543, 'grad_norm': 0.5660075545310974, 'learning_rate': 3.5599774559114475e-05, 'epoch': 3.63}
{'loss': 0.8985, 'grad_norm': 0.5825148820877075, 'learning_rate': 3.45139266054715e-05, 'epoch': 3.65}
{'loss': 0.916, 'grad_norm': 0.6319419741630554, 'learning_rate': 3.344143217776319e-05, 'epoch': 3.67}
{'loss': 0.9054, 'grad_norm': 0.68526291847229, 'learning_rate': 3.238250997259808e-05, 'epoch': 3.7}
{'loss': 0.9006, 'grad_norm': 0.5997857451438904, 'learning_rate': 3.133737591901864e-05, 'epoch': 3.72}
{'loss': 0.9045, 'grad_norm': 0.6088558435440063, 'learning_rate': 3.030624313447067e-05, 'epoch': 3.74}
{'loss': 0.9235, 'grad_norm': 0.626619279384613, 'learning_rate': 2.9289321881345254e-05, 'epoch': 3.76}
{'loss': 0.9021, 'grad_norm': 0.5795537233352661, 'learning_rate': 2.828681952410366e-05, 'epoch': 3.78}
{'loss': 0.861, 'grad_norm': 0.5322035551071167, 'learning_rate': 2.729894048699265e-05, 'epoch': 3.8}
{'loss': 0.8944, 'grad_norm': 0.5576606392860413, 'learning_rate': 2.6325886212359498e-05, 'epoch': 3.83}
{'loss': 0.9004, 'grad_norm': 0.5863828659057617, 'learning_rate': 2.536785511957531e-05, 'epoch': 3.85}
{'loss': 0.8873, 'grad_norm': 0.544672429561615, 'learning_rate': 2.4425042564574184e-05, 'epoch': 3.87}
{'loss': 0.887, 'grad_norm': 0.562516450881958, 'learning_rate': 2.3497640800017685e-05, 'epoch': 3.89}
{'loss': 0.9622, 'grad_norm': 0.581650972366333, 'learning_rate': 2.2585838936091754e-05, 'epoch': 3.91}
{'loss': 0.8929, 'grad_norm': 0.5794907212257385, 'learning_rate': 2.1689822901944457e-05, 'epoch': 3.93}
{'loss': 0.9129, 'grad_norm': 0.593950092792511, 'learning_rate': 2.0809775407772503e-05, 'epoch': 3.96}
{'loss': 0.9012, 'grad_norm': 0.5726704001426697, 'learning_rate': 1.994587590756397e-05, 'epoch': 3.98}
{'loss': 0.9054, 'grad_norm': 0.5793729424476624, 'learning_rate': 1.9098300562505266e-05, 'epoch': 4.0}
{'loss': 0.8967, 'grad_norm': 0.6018264889717102, 'learning_rate': 1.8267222205059308e-05, 'epoch': 4.02}
{'loss': 0.8745, 'grad_norm': 0.5772830843925476, 'learning_rate': 1.74528103037226e-05, 'epoch': 4.02}
{'loss': 0.8585, 'grad_norm': 0.5567143559455872, 'learning_rate': 1.6655230928468258e-05, 'epoch': 4.04}
{'loss': 0.8928, 'grad_norm': 0.5476104617118835, 'learning_rate': 1.587464671688187e-05, 'epoch': 4.07}
{'loss': 0.8764, 'grad_norm': 0.6118549108505249, 'learning_rate': 1.5111216840997743e-05, 'epoch': 4.09}
{'loss': 0.858, 'grad_norm': 0.5500791668891907, 'learning_rate': 1.4365096974841108e-05, 'epoch': 4.11}
{'loss': 0.9035, 'grad_norm': 0.5661054253578186, 'learning_rate': 1.3636439262684298e-05, 'epoch': 4.13}
{'loss': 0.8747, 'grad_norm': 0.5499629974365234, 'learning_rate': 1.2925392288022298e-05, 'epoch': 4.15}
{'loss': 0.856, 'grad_norm': 0.5800081491470337, 'learning_rate': 1.2232101043274436e-05, 'epoch': 4.17}
{'loss': 0.8616, 'grad_norm': 0.5773336291313171, 'learning_rate': 1.1556706900218572e-05, 'epoch': 4.2}
{'loss': 0.8865, 'grad_norm': 0.5993596911430359, 'learning_rate': 1.0899347581163221e-05, 'epoch': 4.22}
{'loss': 0.8986, 'grad_norm': 0.5818606019020081, 'learning_rate': 1.026015713086418e-05, 'epoch': 4.24}
{'loss': 0.8833, 'grad_norm': 0.5653419494628906, 'learning_rate': 9.63926588919083e-06, 'epoch': 4.26}
{'loss': 0.9069, 'grad_norm': 0.5546297430992126, 'learning_rate': 9.036800464548157e-06, 'epoch': 4.28}
[2025-01-10 13:31:25,103] [INFO] [accelerate.accelerator.gather_for_metrics:2509] [PID:2652322] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.
{'eval_loss': 1.0281566381454468, 'eval_runtime': 1.6117, 'eval_samples_per_second': 86.244, 'eval_steps_per_second': 5.584, 'epoch': 4.28}
{'loss': 0.9251, 'grad_norm': 0.5998193025588989, 'learning_rate': 8.4528837080594e-06, 'epoch': 4.3}
{'loss': 0.8634, 'grad_norm': 0.5599220991134644, 'learning_rate': 7.887634688515e-06, 'epoch': 4.33}
{'loss': 0.867, 'grad_norm': 0.5660607218742371, 'learning_rate': 7.341168668092857e-06, 'epoch': 4.35}
{'loss': 0.8785, 'grad_norm': 0.5965206623077393, 'learning_rate': 6.813597078854772e-06, 'epoch': 4.37}
{'loss': 0.8737, 'grad_norm': 0.5826036334037781, 'learning_rate': 6.3050275000238414e-06, 'epoch': 4.39}
{'loss': 0.8821, 'grad_norm': 0.5686428546905518, 'learning_rate': 5.8155636360475385e-06, 'epoch': 4.41}
{'loss': 0.8737, 'grad_norm': 0.5889495015144348, 'learning_rate': 5.345305295450997e-06, 'epoch': 4.43}
{'loss': 0.8687, 'grad_norm': 0.5769639611244202, 'learning_rate': 4.8943483704846475e-06, 'epoch': 4.46}
{'loss': 0.8745, 'grad_norm': 0.6032945513725281, 'learning_rate': 4.462784817570331e-06, 'epoch': 4.48}
{'loss': 0.8444, 'grad_norm': 0.575776219367981, 'learning_rate': 4.050702638550275e-06, 'epoch': 4.5}
{'loss': 0.8991, 'grad_norm': 0.5832281112670898, 'learning_rate': 3.6581858627421027e-06, 'epoch': 4.52}
{'loss': 0.8835, 'grad_norm': 0.5991034507751465, 'learning_rate': 3.2853145298042953e-06, 'epoch': 4.54}
{'loss': 0.8678, 'grad_norm': 0.5373761057853699, 'learning_rate': 2.9321646734147502e-06, 'epoch': 4.57}
{'loss': 0.8884, 'grad_norm': 0.5664764046669006, 'learning_rate': 2.5988083057666533e-06, 'epoch': 4.59}
{'loss': 0.9135, 'grad_norm': 0.6119400858879089, 'learning_rate': 2.2853134028840594e-06, 'epoch': 4.61}
{'loss': 0.8612, 'grad_norm': 0.5999828577041626, 'learning_rate': 1.9917438907606556e-06, 'epoch': 4.63}
{'loss': 0.8793, 'grad_norm': 0.5578993558883667, 'learning_rate': 1.7181596323244454e-06, 'epoch': 4.65}
{'loss': 0.8429, 'grad_norm': 0.5885472893714905, 'learning_rate': 1.4646164152307018e-06, 'epoch': 4.67}
{'loss': 0.8761, 'grad_norm': 0.5885037183761597, 'learning_rate': 1.231165940486234e-06, 'epoch': 4.7}
{'loss': 0.8605, 'grad_norm': 0.5896620750427246, 'learning_rate': 1.0178558119067315e-06, 'epoch': 4.72}
{'loss': 0.8453, 'grad_norm': 0.564673125743866, 'learning_rate': 8.247295264097288e-07, 'epoch': 4.74}
{'loss': 0.8484, 'grad_norm': 0.5469362139701843, 'learning_rate': 6.518264651449779e-07, 'epoch': 4.76}
{'loss': 0.859, 'grad_norm': 0.6399374604225159, 'learning_rate': 4.991818854640395e-07, 'epoch': 4.78}
{'loss': 0.8211, 'grad_norm': 0.5552213788032532, 'learning_rate': 3.6682691373086665e-07, 'epoch': 4.8}
{'loss': 0.8552, 'grad_norm': 0.542849600315094, 'learning_rate': 2.547885389746485e-07, 'epoch': 4.83}
{'loss': 0.8521, 'grad_norm': 0.5803747773170471, 'learning_rate': 1.630896073864352e-07, 'epoch': 4.85}
{'loss': 0.8522, 'grad_norm': 0.5880651473999023, 'learning_rate': 9.174881766043087e-08, 'epoch': 4.87}
{'loss': 0.8754, 'grad_norm': 0.5779021978378296, 'learning_rate': 4.078071718107701e-08, 'epoch': 4.89}
{'loss': 0.8264, 'grad_norm': 0.5512982606887817, 'learning_rate': 1.0195699056669838e-08, 'epoch': 4.91}
{'loss': 0.8451, 'grad_norm': 0.6376991868019104, 'learning_rate': 0.0, 'epoch': 4.93}
{'train_runtime': 88.383, 'train_samples_per_second': 70.319, 'train_steps_per_second': 2.602, 'train_loss': 1.0218796748182049, 'epoch': 4.93}
[2025-01-10 13:31:37,214] [INFO] [axolotl.train.train:205] [PID:2652322] [RANK:0] Training Completed!!! Saving pre-trained model to ./outputs/lora-out[39m
