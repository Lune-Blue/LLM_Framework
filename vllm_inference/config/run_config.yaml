USE_TWO_SERVERS: "no" ## yes or no
FEEDBACK_CUDA_DEVICES: 0,1,2,3
FEEDBACK_MODEL_NAME_OR_PATH: meta-llama/Llama-3.1-8B
FEEDBACK_PORT: "8002"
GENERATE_CUDA_DEVICES: 4,5,6,7
GENERATE_MODEL_NAME_OR_PATH: meta-llama/Llama-3.1-8B
GENERATE_PORT: "8001"

TENSOR_PARALLEL_SIZE: "4"

prompt_key: "base"
use_feedback: "No" ## Yes or No